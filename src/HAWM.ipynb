{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ASkRwEz9_uR"
      },
      "source": [
        "# Requirements.txt\n",
        "Bibliotecas necessárias para construção do Agente:\n",
        "\n",
        "* Langchain\n",
        "* CrewAi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "t1PL1kiuvlzI"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "!pip install crewai['tools']\n",
        "!pip install langchain_mistralai\n",
        "!pip install crewai-tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EYgBuCIgvxhC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from crewai_tools import SerperDevTool\n",
        "from langchain_mistralai import ChatMistralAI\n",
        "from crewai import Agent, Task, Crew, Process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGkLNYsM_RXF"
      },
      "source": [
        "## APIs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUDX--SawP7_"
      },
      "outputs": [],
      "source": [
        "os.environ['MISTRAL_API_KEY'] = userdata.get('MISTRAL')\n",
        "os.environ['SERPER_API_KEY'] = userdata.get('SERPER_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSUzycMJ_UO3"
      },
      "source": [
        "## Criação e Ação dos Agentes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdE5IxOcxHr3"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "def run(start):\n",
        "\n",
        "    import os\n",
        "    from google.colab import userdata\n",
        "    from crewai_tools import SerperDevTool\n",
        "    from langchain_mistralai import ChatMistralAI\n",
        "    from crewai import Agent, Task, Crew, Process\n",
        "\n",
        "    os.environ['MISTRAL_API_KEY'] = userdata.get('MISTRAL')\n",
        "    os.environ['SERPER_API_KEY'] = userdata.get('SERPER_API_KEY')\n",
        "    \n",
        "\n",
        "    search_tool = SerperDevTool()\n",
        "    mistral_model = \"mistral/mistral-large-latest\"\n",
        "\n",
        "    llm = ChatMistralAI(model=mistral_model, temperature=0.7)\n",
        "\n",
        "    researcher = Agent(\n",
        "        role = \"Analista Sênior de Pesquisa em Saúde\",\n",
        "        goal = \"Investigue e relate os últimos avanços em aplicações de IA para o setor de saúde em 2025.\",\n",
        "        backstory = \"\"\"Você trabalha em um importante instituto de pesquisa em saúde.\n",
        "        Sua especialidade é obter e analisar informações sobre tecnologias de IA usadas na área da saúde. Você é excelente em decompor dados médicos complexos e apresentá-los de maneira acessível e esclarecedora.\"\"\",\n",
        "        verbose = False,\n",
        "        allow_delegation = False,\n",
        "        tools = [search_tool],\n",
        "        llm = ChatMistralAI(model=mistral_model, temperature=0)\n",
        "    )\n",
        "    writer = Agent(\n",
        "        role = \"Escritor especialista em tecnologia da saúde\",\n",
        "        goal = \"Elabore artigos concisos e informativos resumindo os últimos avanços em aplicações de IA no setor de saúde em 2025.\",\n",
        "        backstory = \"\"\"Você é um estrategista de conteúdo muito respeitado com um talento especial para criar artigos envolventes e informativos.\n",
        "        Sua especialidade é transformar conceitos complexos de assistência médica e IA em narrativas claras e atraentes, facilmente compreendidas por um público amplo.\"\"\",\n",
        "        verbose = True,\n",
        "        allow_delegation = True,\n",
        "        llm = ChatMistralAI(model=mistral_model, temperature=0)\n",
        "    )\n",
        "\n",
        "    task1 = Task(\n",
        "        description = \"Investigue os avanços mais recentes em aplicações de IA para assistência médica.\",\n",
        "        expected_output = \"Um resumo detalhado das últimas inovações em tecnologia de IA no setor de saúde.\",\n",
        "        agent = researcher\n",
        "    )\n",
        "\n",
        "    task2 = Task(\n",
        "        description = \"Escreva um artigo conciso e informativo destacando as últimas inovações em aplicações de IA para saúde.\",\n",
        "        expected_output = \"Um artigo envolvente e bem estruturado sobre os avanços recentes na tecnologia de IA para a saúde.\",\n",
        "        agent = writer\n",
        "    )\n",
        "\n",
        "    crew = Crew(\n",
        "        agents = [researcher, writer],\n",
        "        tasks = [task1, task2],\n",
        "        verbose = 1\n",
        "    )\n",
        "\n",
        "    final = crew.kickoff()\n",
        "    return final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrNat7o3_PT2"
      },
      "source": [
        "# UI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GWCOzxR-_QGb"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "Vd-m6M3i_2It",
        "outputId": "00ff045f-b8ff-42ec-c00c-cd6f8f1aed44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://9c3c39a6aca15a0828.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://9c3c39a6aca15a0828.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "\n",
        "demo = gr.Interface(fn=run, inputs=\"text\", outputs=\"text\")\n",
        "demo.launch()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
